{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas\n",
    "import ramses2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset format\n",
    "The data be must organized as follow:\n",
    "\n",
    "**- An annotations.csv file with:**\n",
    "\n",
    "**label**: (int) label of the object in the mask image </br>\n",
    "**baseimg**: (string) base image name e.g. \"IM0001\", </br>\n",
    "**x0,y0,x1,y1**: (int) coordinates of the bounding box corners (in pixels, format x0y0x1y1)   </br>\n",
    "**class**: (string) class of the object </br>\n",
    "**res**: (float) resolution in pixels/mm </br>\n",
    "**mass**: (float) mass in g </br>\n",
    "**gt_mass**: True if ground truth mass (individual measure), False if estimated mass </br>\n",
    "**height, width**: (int) image dims </br>\n",
    "\n",
    "**- The images and labeled masks**\n",
    "\n",
    "The files must be in /images and /labels folder. The image and its corresponding labeled masks must have the same basename\n",
    "\n",
    "\n",
    "**- metadata.json**\n",
    "\n",
    "The  metadata.json file contains other information as well as the mass for each batch of aggregates.\n",
    "It contains a list o fimages and a liist o fimage batch with mass.\n",
    "\n",
    "```json\n",
    "{\"images\":[{\n",
    "                \"file_name\": \"IMG1.jpg\",\n",
    "                \"res\": 28.7,\n",
    "                \"height\": 4096,\n",
    "                \"width\": 6144,\n",
    "                \"camera\": \"JAI SW-8000Q\",\n",
    "                \"date\": \"2024-10-09\",\n",
    "                \"tag\": \"CONVEYOR\"\n",
    "            },],\n",
    "    \"batches\":[{\"image_names\":[\"IMG1.jpg\", \"IMG2.jpg\",...],\n",
    "                \"mass\":{\"CLASS1\":111,\"CLASS2\":222}},\n",
    "                {\"image_names\":[\"IMG3.jpg\", \"IMG4.jpg\",...],\n",
    "                \"mass\":{\"CLASS3\":111}},]\n",
    "    }\n",
    "```\n",
    "\n",
    "# DatasetManager class\n",
    "The `ramses2.DatasetManager` class can be used to generate train/test split using one or more dataset folders.\n",
    "\n",
    "Given one or several annotation.csv files, it generates a new CSV file with dataset id and other information as well as a json file containing the filenames of train/valid split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create a new split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Class ids\n",
    "It must be consistent with the network's parameters\n",
    "\n",
    "**Important** : 0 is the reserved index for the background class, do not use it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ra': 1, 'Rc': 2, 'Rb01': 3, 'Rb02': 4, 'Rcu01': 5, 'Ru01': 6, 'Ru02': 7, 'Ru04': 8, 'Ru05': 9, 'Ru06': 10, 'X01': 11, 'Coin': 12, 'X02': 13, 'X03': 14, 'Rg': 15}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# min cls index must be 1 (0 is always bg, it is not needed in the dict)\n",
    "cls_to_idx = {\n",
    "    \"Ra\":1,\n",
    "    \"Rc\":2,\n",
    "    \"Rb01\":3,\n",
    "    \"Rb02\": 4,\n",
    "    \"Rcu01\":5,\n",
    "    \"Ru01\": 6,\n",
    "    \"Ru02\": 7,\n",
    "    \"Ru04\": 8,\n",
    "    \"Ru05\": 9,\n",
    "    \"Ru06\": 10,\n",
    "    \"X01\": 11,\n",
    "    \"Coin\":12,\n",
    "    \"X02\":13,\n",
    "    \"X03\":14,\n",
    "    \"Rg\":15\n",
    "    }\n",
    "\n",
    "# Merge some classes when creating the dataset\n",
    "merging_policy = {\"Ru03\":\"Ru02\",}\n",
    "                #   \"X02\":\"Other\",\n",
    "                #   \"X03\":\"Other\",\n",
    "                #   \"X04\":\"Other\",\n",
    "                #   \"Pl\":\"Other\",\n",
    "                #   \"SHELLS\":\"Other\",\n",
    "                #   \"Rg\":\"Other\",\n",
    "                #   \"UNKNOWN\":\"Other\"}\n",
    "\n",
    "print(cls_to_idx)\n",
    "# id_to_cls={1:\"Agg\",2:\"Coin\",0:\"bg\"}\n",
    "idx_to_cls = {v:k for k, v in cls_to_idx.items()}\n",
    "print(len(cls_to_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters\n",
    "They are needed to generate the dataset and to filters the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3072, 4608)\n",
    "mask_stride = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new Dataset split\n",
    "Here we create a new DatasetManager instance using one or several database folders. </br>\n",
    "We add a column \"_id_\" to tag each dataset and a column \"_folder_\" to indicate where the dataset is stored on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending RASET dataset with 89600 instances\n",
      "Appending SYNTH15CLS dataset with 17875 instances\n",
      "merging class Ru03 and Ru02\n",
      "Found 107475 instances\n",
      "class\n",
      "Rc         27659\n",
      "Ru01       15059\n",
      "Ru02       12095\n",
      "Rb01        8568\n",
      "Ra          8177\n",
      "Ru05        7673\n",
      "Ru04        7302\n",
      "Rb02        5337\n",
      "Ru06        4394\n",
      "X01         3095\n",
      "X02         2199\n",
      "X03         2128\n",
      "Rg          1808\n",
      "Rcu01       1288\n",
      "Coin         429\n",
      "X04          133\n",
      "Pl            55\n",
      "SHELLS        48\n",
      "UNKNOWN       28\n",
      "Name: count, dtype: int64\n",
      "Skipping images []\n",
      "skipping image P20220317_00188 containing box outside the cropped area\n",
      "skipping image P20220322_00010 containing box outside the cropped area\n",
      "skipping image P20220322_00011 containing box outside the cropped area\n",
      "skipping image P20220504_00050 containing box outside the cropped area\n",
      "skipping image P20220504_00053 containing box outside the cropped area\n"
     ]
    }
   ],
   "source": [
    "DS_paths = []\n",
    "DS_paths.append(Path(\"PATH/TO/DATASET1\"))\n",
    "DS_paths.append(Path(\"PATH/TO/DATASET2\"))\n",
    "\n",
    "df = []\n",
    "\n",
    "for i, df_fn in enumerate(DS_paths):\n",
    "    dftemp = pandas.read_csv(df_fn / Path(\"annotations.csv\"), engine='python')\n",
    "    print(f\"Appending {os.path.basename(df_fn)} dataset with {len(dftemp)} instances\")\n",
    "    df.append(dftemp)\n",
    "    # if 'folder' not in df[-1].columns:\n",
    "    df[-1]['folder'] = str(df_fn)\n",
    "    df[-1][\"id\"] = os.path.basename(df_fn)\n",
    "\n",
    "# Merge ru03 and ru02\n",
    "df = pandas.concat(df)\n",
    "for key, target in merging_policy.items():\n",
    "    print(f\"merging class {key} and {target}\")\n",
    "    df[\"class\"] = np.where(df[\"class\"] == key, target, df[\"class\"])\n",
    "print(f\"Found {len(df)} instances\")\n",
    "# print(df)\n",
    "\n",
    "all_cls_names = df[\"class\"].unique().tolist()\n",
    "all_cls_names.sort()\n",
    "\n",
    "print(df[\"class\"].value_counts())\n",
    "\n",
    "dataloader = ramses2.DatasetManager(df,\n",
    "                                   input_shape=input_shape,\n",
    "                                   cls_to_idx=cls_to_idx,\n",
    "                                   mininst=1,\n",
    "                                   maxinst=1000,\n",
    "                                   minres=0,\n",
    "                                   mask_stride=mask_stride,\n",
    "                                   augmentation_func=None,\n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train and valid sets\n",
    "Here we first create a 'valid' dataset using some of the imported datasets:\n",
    "\n",
    "- the argument `contraint='in'` indicates that the image comes from the datasets tagged by `dataset_name=(\"id\", [\"DATASET1\"])`\n",
    "- the classes in `exclude_from_valid` are not included in the dataset\n",
    "- images can be used only once (`max_reuse=0`)\n",
    "- the instances must have a mass value (`mass=True`)\n",
    "- we aim to create a balanced dataset containing 500 instances of each class which is not in the excluded classes. The class \"Coin\" is not submitted to this constraint\n",
    "\n",
    "Then we create a 'train' dataset in 2 times:\n",
    "- First we use `dataset_name=(\"id\", [\"DATASET1])` with a posible oversampling `max_reuse=2`\n",
    "- Then we append images from `[\"DATASET2\"]` with no oversampling.\n",
    "- Instances without mass data are included in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating valid set with an objective of 500 training intances in ['RASET']\n",
      "Using 1733 images\n",
      "Adding images, iteration 1     \n",
      "Ended in 1 iterations.\n",
      " Added 273 images. Instances per class: {'Coin': 0, 'Pl': 0, 'Ra': 500, 'Rb01': 500, 'Rb02': 500, 'Rc': 500, 'Rcu01': 0, 'Rg': 0, 'Ru01': 500, 'Ru02': 500, 'Ru04': 500, 'Ru05': 500, 'Ru06': 500, 'SHELLS': 0, 'UNKNOWN': 0, 'X01': 500, 'X02': 0, 'X03': 0, 'X04': 0} \n",
      "\n",
      "Creating train set with an objective of 20000 training intances in ['RASET']\n",
      "Using 2145 images\n",
      "Adding images, iteration 1     \n",
      "Adding images, iteration 2     \n",
      "Ended in 2 iterations.\n",
      " Added 3215 images. Instances per class: {'Coin': 550, 'Pl': 0, 'Ra': 13547, 'Rb01': 14378, 'Rb02': 6359, 'Rc': 20000, 'Rcu01': 1085, 'Rg': 271, 'Ru01': 20000, 'Ru02': 19988, 'Ru04': 10207, 'Ru05': 10885, 'Ru06': 4733, 'SHELLS': 0, 'UNKNOWN': 0, 'X01': 2512, 'X02': 1152, 'X03': 1492, 'X04': 0} \n",
      "\n",
      "Creating train set with an objective of 10000 training intances in ['SYNTH15CLS']\n",
      "Using 200 images\n",
      "Adding images, iteration 1     \n",
      "Ended in 1 iterations.\n",
      " Added 200 images. Instances per class: {'Coin': 119, 'Pl': 0, 'Ra': 868, 'Rb01': 773, 'Rb02': 1595, 'Rc': 749, 'Rcu01': 741, 'Rg': 1663, 'Ru01': 814, 'Ru02': 1481, 'Ru04': 1619, 'Ru05': 1680, 'Ru06': 1503, 'SHELLS': 0, 'UNKNOWN': 0, 'X01': 1298, 'X02': 1613, 'X03': 1359, 'X04': 0} \n",
      "\n",
      "Appending images and instances to train/valid sets\n",
      "\n",
      "Number of images: 3415\n"
     ]
    }
   ],
   "source": [
    "exclude_from_valid = ['UNKNOWN', 'Rcu01', 'Coin', \"X02\", \"X03\", \"X04\", \"Pl\", \"SHELLS\", \"Rg\"]\n",
    "exclude_from_training = ['UNKNOWN', \"X04\", \"Pl\", \"SHELLS\"]\n",
    "\n",
    "dataloader.seed = 4\n",
    "# First generate valid set with only mass data\n",
    "dataloader.create_set(subset=\"valid\", n=500, exclude=exclude_from_valid, not_counting=[\"Coin\"],\n",
    "                       max_reuse=0, append=False, seed=None, dataset_name=(\"id\", [\"DATASET1\"]), constraint='in', mass=True)\n",
    "# dataloader.create_set(subset=\"valid\", n=300, exclude=exclude_from_valid, not_counting=[\"Coin\"],\n",
    "#                        max_reuse=0, append=True, seed=None, dataset_name=(\"id\", [\"SYNTH2\"]), constraint='in', mass=False)\n",
    "\n",
    "# Then train data using reuse=2 to balance the set\n",
    "dataloader.create_set(subset=\"train\", n=20000, exclude=exclude_from_training, not_counting=[\"Coin\"],\n",
    "                       max_reuse=2, append=False, seed=None, dataset_name=(\"id\", [\"DATASET1\"]), constraint='in', mass=False)\n",
    "dataloader.create_set(subset=\"train\", n=10000, exclude=exclude_from_training, not_counting=[\"Coin\"],\n",
    "                       max_reuse=0, append=True, seed=None, dataset_name=(\"id\", [\"DATASET2\"]), constraint=\"in\", mass=False)\n",
    "\n",
    "\n",
    "print(\"\\nNumber of images:\",len(dataloader.train_basenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset split and annotations\n",
    "It generates two files: \n",
    "- a myfilename.csv annotations files with additionnal columns\n",
    "- a myfilename.json files with two lists containing the images in train and valid subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspath = Path(\"/PATH/TO/NEW/DATASET\")\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "name = f\"DATASET_NAME_{now}\"\n",
    "dataloader.save(os.path.join(dspath, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Annotations stats\n",
      "Indexes: {'Ra': 1, 'Rc': 2, 'Rb01': 3, 'Rb02': 4, 'Rcu01': 5, 'Ru01': 6, 'Ru02': 7, 'Ru04': 8, 'Ru05': 9, 'Ru06': 10, 'X01': 11, 'Coin': 12, 'X02': 13, 'X03': 14, 'Rg': 15}\n",
      "Number of instances: 107475\n",
      "         count      freq.\n",
      "class                    \n",
      "Rc       27659  25.735287\n",
      "Ru01     15059  14.011631\n",
      "Ru02     12095  11.253780\n",
      "Rb01      8568   7.972087\n",
      "Ra        8177   7.608281\n",
      "Ru05      7673   7.139335\n",
      "Ru04      7302   6.794138\n",
      "Rb02      5337   4.965806\n",
      "Ru06      4394   4.088393\n",
      "X01       3095   2.879739\n",
      "X02       2199   2.046057\n",
      "X03       2128   1.979995\n",
      "Rg        1808   1.682252\n",
      "Rcu01     1288   1.198418\n",
      "Coin       429   0.399163\n",
      "X04        133   0.123750\n",
      "Pl          55   0.051175\n",
      "SHELLS      48   0.044662\n",
      "UNKNOWN     28   0.026053\n",
      "\n",
      "Train dataset stats\n",
      "number of images in training set: 3472\n",
      "number of unique images in training set: 2194\n",
      "number of instances per class\n",
      "{'Coin': 668, 'Pl': 0, 'Ra': 14416, 'Rb01': 15145, 'Rb02': 7952, 'Rc': 20749, 'Rcu01': 1825, 'Rg': 1934, 'Ru01': 20814, 'Ru02': 21474, 'Ru04': 11821, 'Ru05': 12557, 'Ru06': 6237, 'SHELLS': 0, 'UNKNOWN': 0, 'X01': 3804, 'X02': 2765, 'X03': 2851, 'X04': 0}\n",
      "Valid dataset stats\n",
      "number of images in valid set: 258\n",
      "number of unique images in valid set: 258\n",
      "number of instances per class\n",
      "{'Coin': 0, 'Pl': 0, 'Ra': 500, 'Rb01': 500, 'Rb02': 499, 'Rc': 500, 'Rcu01': 0, 'Rg': 0, 'Ru01': 500, 'Ru02': 500, 'Ru04': 500, 'Ru05': 500, 'Ru06': 499, 'SHELLS': 0, 'UNKNOWN': 0, 'X01': 500, 'X02': 0, 'X03': 0, 'X04': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Full Annotations stats\")\n",
    "print(\"Indexes:\", dataloader.cls_to_idx)\n",
    "stats = pandas.DataFrame(dataloader.annotations[\"class\"].value_counts())\n",
    "print(\"Number of instances:\", len(dataloader.annotations))\n",
    "stats[\"freq.\"] = 100 * stats[\"count\"] / stats[\"count\"].sum()\n",
    "print(stats)\n",
    "\n",
    "if len(dataloader.train_basenames) > 0:\n",
    "    print(\"\\nTrain dataset stats\")\n",
    "    print(\"number of images in training set:\", len(dataloader.train_basenames))\n",
    "    print(\"number of unique images in training set:\", np.unique(dataloader.train_basenames).size)\n",
    "    print(\"number of instances per class\")\n",
    "    print(dataloader.train_class_counts)\n",
    "\n",
    "if len(dataloader.valid_basenames) > 0:\n",
    "    print(\"Valid dataset stats\")\n",
    "    print(\"number of images in valid set:\", len(dataloader.valid_basenames))\n",
    "    print(\"number of unique images in valid set:\", np.unique(dataloader.valid_basenames).size)\n",
    "    print(\"number of instances per class\")\n",
    "    print(dataloader.valid_class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set statistics\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain set statistics\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ntot = \u001b[43mnp\u001b[49m.sum([n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m dataloader.train_class_counts.values()])\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c, n \u001b[38;5;129;01min\u001b[39;00m dataloader.train_class_counts.items():\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Train set statistics\")\n",
    "ntot = np.sum([n for n in dataloader.train_class_counts.values()])\n",
    "for c, n in dataloader.train_class_counts.items():\n",
    "    if n > 0:\n",
    "        print(f\"{c:8s} {n:6d}  {100*n/ntot:4.2f}%\")\n",
    "print(\"\\nTest set statistics\")\n",
    "ntot = np.sum([n for n in dataloader.valid_class_counts.values()])\n",
    "for c, n in dataloader.valid_class_counts.items():\n",
    "    if n > 0:\n",
    "        print(f\"{c:8s} {n:6d}  {100*n/ntot:4.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an existing dataset split and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train dataset stats\n",
      "number of images in training set: 2897\n",
      "number of unique images in training set: 1750\n",
      "number of instances per class\n",
      "{'Coin': 549, 'Pl': 0, 'Ra': 13539, 'Rb01': 14270, 'Rb02': 6348, 'Rc': 19749, 'Rcu01': 1056, 'Rg': 271, 'Ru01': 19843, 'Ru02': 14246, 'Ru04': 10193, 'Ru05': 10876, 'Ru06': 4734, 'SHELLS': 0, 'UNKNOWN': 0, 'X01': 2506, 'X02': 1148, 'X03': 1492, 'X04': 0}\n",
      "Valid dataset stats\n",
      "number of images in valid set: 258\n",
      "number of unique images in valid set: 258\n",
      "number of instances per class\n",
      "{'Coin': 0, 'Pl': 0, 'Ra': 500, 'Rb01': 500, 'Rb02': 499, 'Rc': 500, 'Rcu01': 0, 'Rg': 0, 'Ru01': 500, 'Ru02': 500, 'Ru04': 500, 'Ru05': 500, 'Ru06': 499, 'SHELLS': 0, 'UNKNOWN': 0, 'X01': 502, 'X02': 0, 'X03': 0, 'X04': 0}\n"
     ]
    }
   ],
   "source": [
    "ds_path = Path(\"../datasets\")\n",
    "ds_name = \"15CLS_20250723-173206_MASS_ONLY\"\n",
    "\n",
    "dataloader = ramses2.DatasetManager.from_file(\n",
    "    annfile=ds_path / Path(ds_name + \".csv\"), filename=ds_path / Path(ds_name + \".json\"),\n",
    ")\n",
    "if len(dataloader.train_basenames) > 0:\n",
    "    print(\"\\nTrain dataset stats\")\n",
    "    print(\"number of images in training set:\", len(dataloader.train_basenames))\n",
    "    print(\"number of unique images in training set:\", np.unique(dataloader.train_basenames).size)\n",
    "    print(\"number of instances per class\")\n",
    "    print(dataloader.train_class_counts)\n",
    "\n",
    "if len(dataloader.valid_basenames) > 0:\n",
    "    print(\"Valid dataset stats\")\n",
    "    print(\"number of images in valid set:\", len(dataloader.valid_basenames))\n",
    "    print(\"number of unique images in valid set:\", np.unique(dataloader.valid_basenames).size)\n",
    "    print(\"number of instances per class\")\n",
    "    print(dataloader.valid_class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of filtering: keep only instances with mass data in train/test/ splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.filter_set(hasmass=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Filtered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.save(os.path.join(ds_path,\"15CLS_20250723-173206_MASS_ONLY\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
